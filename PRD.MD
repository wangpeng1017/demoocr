
## **产品需求文档 (PRD)：商品标签多模型结构化信息提取能力测试工具**

### 1. **项目概述**

#### 1.1. **项目背景与目标**

随着多模态大模型的发展，我们希望快速、直观地评估不同顶尖模型对商品标签进行**结构化信息提取**（例如，识别并提取商品名称和价格）的能力。为了便于效果对比，需要开发一个简单的Web应用，能够同时调用多个主流模型服务，并行处理用户上传的、**可能包含多个商品标签**的图片或视频，并在同一界面以结构化的形式展示各自的提取结果。

本项目旨在**最快速度实现核心功能**，优先考虑开发效率和快速部署，因此在技术选型上力求精简。

#### 1.2. **目标用户**

- **开发人员/算法工程师**：需要评估和选择最适合业务场景的视觉信息提取模型。
- **产品经理/测试人员**：需要验证和比较不同模型供应商在复杂场景下的结构化信息提取效果。

### 2. **功能需求 (Functional Requirements)**

#### 2.1. **用户界面 (UI)**

- **2.1.1. 文件上传区**:
    - 支持用户通过点击或拖拽方式上传文件。
    - 明确支持的文件格式：
        - **图片**: `.jpg`, `.jpeg`, `.png`, `.webp`
        - **视频**: `.mp4`, `.mov`, `.webm`
    - 上传后，应有加载（loading）或处理中的状态提示。

- **2.1.2. 结果展示区**:
    - 以卡片或列的形式，清晰地并排展示每个模型的识别结果。
    - 每个模型的结果区应包含：
        - **模型名称**: 百度OCR、阿里OCR、GLM-4V、Gemini 2.5 Pro、Gemini 2.5 Flash。
        - **结构化结果**:
            - 对于能够进行信息提取的模型（GLM-4V, Gemini系列），结果应以列表或表格形式展示所有识别出的商品标签。
            - 每个标签应清晰地展示提取出的字段：**【商品名称】**和**【价格】**。
            - **示例**:
                - 标签1: { 商品名称: "经典口味薯片", 价格: "¥8.50" }
                - 标签2: { 商品名称: "鲜橙味汽水", 价格: "¥5.00" }
        - **原始识别文本** (可选但建议): 提供一个折叠或切换按钮，以查看模型返回的未经处理的纯文本，方便对比。
        - **处理耗时** (可选): 显示从接收请求到返回结果的时间。

#### 2.2. **核心功能**

- **2.2.1. 输入处理**:
    - **图片输入**: 直接将图片文件发送至各模型的API进行处理。
    - **视频输入**:
        - 系统需要在后端自动对上传的视频进行抽帧处理（例如，每秒抽取1帧）。
        - 将抽取的关键帧图片并行发送给各个模型进行识别。
        - **结果聚合**: 后端需要对从视频所有帧中提取出的结构化信息进行汇总和去重，最终展示一个包含视频中所有不重复商品标签的完整列表。

- **2.2.2. 并行模型调用与信息提取**:
    - 用户上传文件后，后端应**同时**向所有模型的API端点发送请求。
    - **模型调用逻辑区分**:
        - **对于多模态大模型 (GLM-4V, Gemini 2.5 Pro, Gemini 2.5 Flash)**:
            - 调用其多模态视觉理解API。
            - **请求中需包含特定的指令 (Prompt)，要求模型在识别图片中所有商品标签的同时，以结构化的JSON格式返回每个标签的『商品名称』和『价格』。**
            - **期望的JSON输出格式示例**:
              ```json
              [
                { "product_name": "商品A", "price": "19.99" },
                { "product_name": "商品B", "price": "25.00" }
              ]
              ```
        - **对于传统OCR模型 (百度OCR, 阿里OCR)**:
            - 调用其通用文字识别API，获取包含文字内容和位置信息的原始识别结果。
            - 由于这类模型本身不具备直接结构化输出的能力，其结果将作为“原始文本”进行展示，用于对比基础的文字识别准确率。

- **2.2.3. 结果整合与展示**:
    - 后端需要整合所有模型返回的结果（结构化JSON或纯文本），并以统一的数据结构返回给前端。
    - 前端动态解析返回的数据，将结构化信息渲染成清晰的列表或表格，并将纯文本结果展示在对应的区域。

### 3. **非功能需求 (Non-Functional Requirements)**

#### 3.1. **开发与部署**

- **3.1.1. 快速实现**:
    - 界面设计力求简洁，可以使用现成的UI组件库（如 Shadcn/UI, NextUI, 或 antd）来加速开发。
    - 优先采用前后端一体化的框架（如 Next.js）以简化开发流程，完美契合 Vercel 部署。

- **3.1.2. Vercel 部署**:
    - 项目需能直接通过 Vercel 平台进行部署。后端逻辑应通过 Vercel Functions (Serverless Functions) 实现。
    - 所有API密钥和敏感配置必须通过 Vercel 的环境变量进行管理，严禁硬编码。

#### 3.2. **系统架构**

- **3.2.1. 无状态与无数据库**:
    - **无需用户登录**：项目为公开的工具，不设用户系统。
    - **优先无数据库**：处理过程是即时的，请求处理完即可丢弃数据，原则上**不需要数据库**。如需扩展，可选用 Vercel KV 或 Vercel Postgres。

- **3.2.2. API直接调用**:
    - 所有模型均通过其官方提供的API进行调用。后端需封装好对这些API的请求逻辑，包括认证、参数构造（**特别是为多模态模型构造Prompt**）和错误处理。

### 4. **技术栈建议**

- **前端**: React (强烈推荐使用 **Next.js** 框架)
- **后端**: Vercel Functions (Serverless), 使用 **Node.js/TypeScript** 编写。
- **UI库**: Shadcn/UI, NextUI, Tailwind CSS
- **API密钥管理**: Vercel Environment Variables
- **部署平台**: Vercel

### 5. **开发步骤建议 (For Cursor)**

1.  **初始化项目**: 使用 `create-next-app` 初始化一个 Next.js 项目。
2.  **前端界面搭建**:
    - (可以提示Cursor): "帮我用Next.js, TypeScript和Tailwind CSS创建一个页面，包含一个文件上传区域和五个并排的卡片用于展示结果。每个卡片里要能显示一个商品列表，包含商品名和价格。"
3.  **后端API路由创建**:
    - 在 Next.js 的 `app/api` 目录下创建处理函数（Route Handler），用于接收前端上传的文件。
4.  **封装模型调用逻辑**:
    - 为每个模型分别创建调用函数。
    - (可以提示Cursor): "**帮我写一个TypeScript函数，用于调用Google Gemini 2.5 Pro API。这个函数需要接收一张图片，并使用prompt来指示模型查找图片中所有的商品标签，最后以一个包含product_name和price字段的JSON数组格式返回结果。**"
    - 对百度和阿里OCR，则创建调用其通用识别API的函数。
5.  **实现并行处理与结果聚合**:
    - 在主API路由中，使用 `Promise.allSettled` 来并行触发对所有模型的API调用，确保即使某个模型失败，其他模型的结果也能返回。
    - 整合不同模型的返回结果（JSON或纯文本）到一个统一的对象中再返回给前端。
6.  **处理视频输入**:
    - 引入一个轻量级的视频处理库（如 `ffmpeg.wasm` 或在serverless环境寻找合适的抽帧方案）在后端进行抽帧。
7.  **连接前后端**:
    - 在前端页面中，实现文件上传后调用后端API，并使用获取到的数据动态渲染结果列表。
8.  **部署到Vercel**:
    - 将代码推送到 GitHub/GitLab。
    - 在 Vercel 上关联该代码仓库，并配置好所有模型的API密钥作为环境变量。Vercel将自动完成部署。